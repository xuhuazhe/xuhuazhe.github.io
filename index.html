<!DOCTYPE html>
<html lang="en">
<head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src="https://www.googletagmanager.com/gtag/js?id=G-2ZFRQHQYP1"></script>
	<script>
	  window.dataLayer = window.dataLayer || [];
	  function gtag(){dataLayer.push(arguments);}
	  gtag('js', new Date());

	  gtag('config', 'G-2ZFRQHQYP1');
	</script>
	<link rel="stylesheet" type="text/css" href="./style/css">
	<link rel="stylesheet" type="text/css" href="./style/bootstrap.min.css">
	<link rel="stylesheet" type="text/css" href="./style/styles.css">
	<script src=""></script>
	<title>Huazhe Xu</title>
</head>

<body>

	<div class="my-container">
		<h1> Huazhe Xu（许华哲） </h1>
		<span>  <a href="https://scholar.google.com/citations?user=t9HPFawAAAAJ&hl=en">[Google Scholar]</a> <a href="https://twitter.com/HarryXu12">[Twitter]</a>  </span>

		<div class="btn-group btn-group-justified" role="group" aria-label="Justified button group">
			<a href="index.html" class="btn btn-default" role="button">Home</a>
			<a href="publication.html" class="btn btn-default" role="button">Publication</a>
			<a href="group.html" class="btn btn-default" role="button">Group</a>
			<a href="contact.html" class="btn btn-default" role="button">Contact</a>
			<a href="misc.html" class="btn btn-default" role="button">Misc</a>
    	</div>

    	<div class="content">
    		<div class="row">
				<div class="col-sm-4">
					<img class="img-responsive img-rounded" src="images/me2.jpeg">
				</div>
				<div class="col-sm-8">
					<p> I am a Tenure-Track Assistant Professor at <a href="https://iiis.tsinghua.edu.cn/en/">Institute for Interdisciplinary Information Sciences (IIIS), Tsinghua University</a>. I am leading the Tsinghua Embodied AI Lab (TEA Lab, <a href="images/pub-pic/tea.jpg">logo</a>), where we build robots and then bring intelligence to robots. </p>
					<p>I was a postdoctoral researcher at <a href="http://svl.stanford.edu/">Stanford Vision and Learning Lab (SVL)</a> advised by Prof. <a href="https://jiajunwu.com/">Jiajun Wu</a>. I obtained my Ph.D. in <a href="https://bair.berkeley.edu/">Berkeley AI Research (BAIR)</a> advised by Prof. <a href="https://people.eecs.berkeley.edu/~trevor/">Trevor Darrell</a>. I obtained my bachelor degree from Tsinghua University (major in EE, minor in Management).</p>


<!--						I will be a postdoctoral fellow in <a href="https://ai.stanford.edu/">Stanford Artificial Intelligence Lab (SAIL)</a> from 2021 summer to 2022 summer. </p>-->

					<p><strong> I am hiring self-motivated Postdocs, Ph.D. students, Undergrads, and Research Interns at Tsinghua (base: Beijing, Shanghai). See more details in Chinese <a href="https://zhuanlan.zhihu.com/p/474615424">here</a>.</strong></p>
					<p><strong> I am also hiring talented engineers and interns in an embodied AI startup.</strong></p>
					<p><strong> Please email me with your CV directly. </strong> </p>


					<p>I support <a href="http://slow-science.org/">Slow Science</a>.
				</div>
    		</div>
        <h3>Research Topics</h3>
        <p>I am interested in <strong>Embodied AI</strong>: <strong>Reinforcement Learning</strong>, <strong>Robotics</strong>, and <strong>Computer Vision/Touch</strong>. Specifically, my research focuses on modeling the dynamics of the world, leveraging/finding human priors for policy learning, and further enabling algorithms to learn in a sample-efficient manner and generalize to unseen scenarios. I am also interested in solving complex real robot applications with deep learning and reinforcement learning. </p>

        <h3>News</h3>
        <ul>
			<li><p>Two papers (<a href="https://demospeedup.github.io/">DemoSpeedUp</a>, <a href="https://facet.pages.dev/#/">FACET</a>) are accepted by CoRL'25. </p></li>
			<li><p>Our paper <a href="https://reactive-diffusion-policy.github.io/">RDP</a> won <strong style="color:red">best student paper finalist</strong> at RSS'25. </p></li>
			<li><p>Our paper <a href="https://reactive-diffusion-policy.github.io/">RDP</a> won <strong style="color:red">best paper</strong> at ICRA'25 Beyond Pick and Place Workshop. </p></li>
			<li><p>Our paper <a href="https://demo-generation.github.io/">DemonGen</a> won <strong style="color:red">best long paper</strong> at CVPR'25 Syn4CV Workshop. </p></li>
			<li><p>I gave three invited talks at RSS workshops. </p></li>
			<li><p>I won AI100 Pioneers from DeepTech and MIT Tech Review in China. </p></li>
			<li><p>I served as a session chair and a mentor in ICLR'25. </p></li>
			<li><p>Two papers (<a href="https://suninghuang19.github.io/mentor_page/">MENTOR</a>, <a href="https://openreview.net/pdf?id=VhmTXbsdtx">FoG</a>) are accepted by ICML'25. </p></li>
			<li><p>Four papers (<a href="https://demo-generation.github.io/">DemoGen</a>, <a href="https://do-glove.github.io/">DOGlove</a>, <a href="https://reactive-diffusion-policy.github.io/">RDP</a>, <a href="https://www.roboticsproceedings.org/rss21/p080.pdf">Meopheus</a>) are accepted by RSS'25. </p></li>
			<li><p>The paper <a href="https://tea-lab.github.io/TwoByTwo/">TwoByTwo</a> is accepted by CVPR'25. </p></li>
			<li><p><a href="https://arxiv.org/pdf/2406.07381">DLLM</a> is accepted by NAACL'25. </p></li>
			<li><p>I am invited to Boao Forum for Asia as a roundtable speaker.  </p></li>
			<li><p>Four papers (<a href="https://densematcher.github.io/">DenseMatcher</a>(<strong style="color:red">spotlight</strong>), <a href="https://hukz18.github.io/Stem-Ob/">Stem-OB</a>(<strong style="color:red">spotlight</strong>), <a href="https://robots-pretrain-robots.github.io/">Robots Pre-Train Robots</a>, <a href="https://openreview.net/pdf?id=fNMKqyvuZT">Looking Backward</a>) are accepted by ICLR'25. </p></li>
			<li><p>Two papers (<a href="https://mobile-dex-catch.github.io/">Catch It!</a>, <a href="https://hard-to-sim.github.io/">Power-Saving Quadruped</a>) are accepted by ICRA'25. </p></li>
			<li><p>I serve as an area chair for IJCAI'25. </p></li>
			<li><p>Two papers (<a href="https://cheryyunl.github.io/make-an-agent/">Make-An-Agent</a>, <a href="https://jackhck.github.io/keygrid.github.io/">KeyGrid</a>) are accepted by NeurIPS'24. </p></li>
			<li><p>I serve as an associate editor for ICRA'25. </p></li>
			<li><p>Three papers (<a href="https://maniwhere.github.io/">Maniwhere</a>, <a href="https://riemann-web.github.io/">RiEMann</a>, <a href="https://gensim2.github.io/">GenSim2</a>) are accepted by CoRL'24. </p></li>
			<li><p>I serve as an area chair for ICLR'25. </p></li>
			<li><p>I won Yunfan "Brilliant Star" Award in World Artificial Intelligence Conference (WAIC) 2024. </p></li>
			<li><p>Two papers (<a href="https://tea-lab.github.io/Robo-ABC/">RoboABC</a>, <a href="https://diffusion-reward.github.io/">Diffusion Reward</a>) are accepted by ECCV'24. </p></li>
			<li><p><a href="https://zhengmaohe.github.io/leg-manip/">V-Loco-Manip</a> is accepted by IROS'24. </p></li>
			<li><p><a href="https://ace-rl.github.io/">ACE</a> and <a href="https://arxiv.org/html/2405.19080v1">OMPO</a> are selected as <strong style="color:red">oral</strong> presentations in ICML'24.</p></li>
			<li><p><a href="https://3d-diffusion-policy.github.io/">DP3</a> is accepted by RSS'24. </p></li>
			<li><p>Six papers (<a href="https://arxiv.org/pdf/2405.17358">Rethinking Transformers in Solving POMDPs</a>, <a href="https://arxiv.org/html/2405.19080v1">OMPO</a>, <a href="https://github.com/PremierTACO/premier-taco">Premier-TACO</a>, <a href="https://jity16.github.io/BEE/">BEE</a>, <a href="https://arxiv.org/html/2405.18520v1">OBAC</a>, <a href="https://ace-rl.github.io/">ACE</a>) are accepted by ICML'24. </p></li>
			<li><p>I serve as a meta-reviewer in <a href="https://roboticsconference.org/program/pioneers/">Pioneers Workshop</a> in RSS'24. </p></li>
			<li><p>Three papers (<a href="https://steven-xzr.github.io/ArrayBot/">Arraybot</a>, <a href="">DeformNet</a>, <a href="https://sites.google.com/view/hiro-hand/%E9%A6%96%E9%A1%B5">HIRO Hand</a>) are accepted by ICRA'24. </p></li>
			<li><p>Six papers (<a href="https://xugw-kevin.github.io/drm/">DrM (<strong style="color:red">spotlight</strong>)</a>, <a href="https://liruiw.github.io/gensim/">GenSim(<strong style="color:red">spotlight</strong>)</a>, <a href="https://lei-kun.github.io/uni-o4/">Uni-O4</a>, <a href="https://lamo2023.github.io/">LaMo</a>, <a href="https://arxiv.org/abs/2310.07220">COPlanner</a>, <a href="https://openreview.net/pdf?id=MpyFAhH9CK">MorphMaze</a>) are accepted by ICLR'24. </p></li>
			<li><p>I serve as a reviewer in Science Robotics. </p></li>
			<li><p>I serve as a Senior PC in IJCAI'24. </p></li>
			<li><p><a href="https://linchangyi1.github.io/9DTact/">9DTact</a> is accepted by RA-L with a presentation at ICRA'24. </p></li>
			<li><p>I served as session chairs at DAI and X-AGI conference. I also will give a tutorial on RL at DAI.</p></li>
			<li><p>I gave a talk about Embodied AI at <strong style="color:red"><a href="https://yixi.tv/#/speech/detail?id=1232">YiXi</a></strong>@Shenzhen. </p></li>
			<li><p>RoboCraft (3D version) is accepted by IJRR. </p></li>
			<li><p>Our paper <a href="https://hshi74.github.io/robocook/">RoboCook</a> won <strong style="color:red">best system paper award</strong> at CoRL'23. </p></li>
			<li><p>Our paper <a href="https://liruiw.github.io/gensim/">GenSim</a> won <strong style="color:red">outstanding paper award</strong> in LangRob workshop at CoRL'23. </p></li>
			<li><p>I serve as an associate editor in ICRA'24. </p></li>
			<li><p>Six papers (<a href="https://gemcollector.github.io/RL-ViGen/">RL-ViGen</a>, <a href="https://ruijiezheng.com/project/TACO/index.html">TACO</a>, <a href="https://lfvoid-rl.github.io/">LfVoid</a>, <a href="https://yangsizhe.github.io/MoVie/">MoVie</a>, <a href="https://yanjieze.com/H-InDex/">H-InDex</a>, <a href="https://arxiv.org/pdf/2306.14534v1.pdf">CEIL</a>) are accepted by NeurIPS'23 including 1 in dataset and benchmark track. </p></li>
			<li><p><a href="https://arxiv.org/pdf/2309.06276.pdf">OTAS</a> is accepted by WACV'24. </p></li>
			<li><p>RoboCook is accepted by CoRL'23 (<strong style="color:red">oral</strong>). </p></li>
			<li><p><a href="https://github.com/gemcollector/learning-from-scratch">Pretrain-or-not-pretrain</a> is accepted by ICML'23. </p></li>
			<li><p>I will serve as an SPC member in IJCAI'23. </p></li>
			<li><p>Four papers (<a href="https://arxiv.org/abs/2303.03391">DeFog</a>, <a href="https://sites.google.com/view/emergent-action-representation/">EAR</a>, <a href="https://arxiv.org/abs/2210.13542">ScalingDiffPlanning</a>, <a href="https://ruijiezheng.com/project/mbrl_lipschitz/index.html">no-ensemble-mbrl</a>) are accepted by ICLR'23. </p></li>
			<li><p>Four papers(<a href="https://sites.google.com/view/useek/">USEEK</a>, <a href="https://sites.google.com/view/dtact-sensor">DTact</a>, <a href="https://sites.google.com/view/eil-website">EIL</a>, <a href="https://panchaoyi.com/efficient-bimanual-handover-and-rearrangement-via-symmetry-aware-actor-critic-learning">Bimanual Handover</a>) are accepted by ICRA'23. </p></li>
			<li><p>Two papers are accepted by NeurIPS'22 (<a href="https://sites.google.com/view/pie-g/home">PIE-G</a>, <a href="https://sites.google.com/view/e-mapp">EMAPP</a>, 2 <strong style="color:red">spotlights</strong>). </p></li>
			<li><p>One paper (<a href="https://ai.stanford.edu/~rhgao/see_hear_feel/">see-hear-feel</a>) is accepted by CoRL'22. </p></li>
			<li><p>Our paper <a href="https://lijiaman.github.io/projects/summon/">SUMMON</a> is accepted by Siggraph Asia'22. </p></li>
			<li><p>Our paper "Towards Learning to Play Piano with Dexterous Hands and Touch" is accepted by IROS'22. </p></li>
			<li><p>Our RSS paper "RoboCraft" is covered by <a href="https://news.mit.edu/2022/robots-play-play-dough-0623">MIT Tech Review</a> and <a href="https://hai.stanford.edu/news/training-robot-shape-letters-play-doh">HAI</a>. </p></li>
			<li><p>Two papers are accepted by ICML'22. </p></li>
			<li><p>Our paper "Don't Touch What Matters" is accepted by IJCAI'22. </p></li>
			<li><p>I gave a talk at UC San Diego. </p></li>
			<li><p>Our paper RoboCraft is accepted by RSS'22. </p></li>
			<li><p>One paper is accepted by ICLR'22 (<strong style="color:red">spotlight</strong>). </p></li>
			<li><p>Two papers are accepted by NeurIPS'21. </p></li>
			<li><p>I became Dr. Xu on May 15, 2021. </p></li>
			<li><p>I gave a talk at MSRA, March 10, 2021. </p></li>
			<li><p>One paper is accepted by CVPR'21. </p></li>
			<li><p>Two papers are accepted by ICRA'21. </p></li>
			<li><p>Two papers are accepted by ICLR'21. </p></li>
			<li><p>I gave a talk at Nvidia, Nov, 2020. </p></li>
			<li><p>One papers is accepted by NeurIPS'20. </p></li>
			<li><p>One papers is accepted by ECCV'20. </p></li>
			<li><p>One papers is accepted by ICML'20 (<strong style="color:red">oral</strong>). </p></li>
        </ul>



    	</div>
      <br>
			<br>
      <br>
			<br>
      <br>
			<br>

    	<footer>
            <span>&copy;2022 Huazhe Xu with thanks to <a href="http://bootsnipp.com/" rel="nofollow">Bootsnipp</a>.</span>
        </footer>

	</div>

</body>
</html>
