<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Huazhe(Harry) Xu's Homepage</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <link rel="stylesheet" href="stylesheets/bootstrap.min.css">
    
    <meta name="viewport" content="width=device-width">
    
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1>Huazhe(Harry) Xu</h1>
		<img src="images/me.jpeg"></img>
		<br />
		<br />
        <p>  <a href="http://tts.imtranslator.net/XMo1">How to pronounce my name?</a><br />
		In the Wade-Giles system of romanization, it is rendered as Huache Tsu.<br />
		In Chinese characters, it is 许华哲.</p>
        <p class="view"><a href="mailto:xuhuazhe12@gmail.com">xuhuazhe12@gmail.com</a></p>
        <p class="view"><a href="./Huazhe_Xu_CV.pdf">Download my CV</a></p>
	<p class="view"><a href="https://scholar.google.com/citations?user=t9HPFawAAAAJ&hl=en">google scholar</a></p>
      </header>


      <section>
	    <h2>About Me</h2>
			<p>I am a third year Ph.D student in BAIR (Berkeley AI Research) advised by Prof. Trevor Darrell. I am also working as an intern researcher in Facebook AI Research with Prof. Tengyu Ma and Yuandong Tian. I used to be an undergraduate student in <a href="http://www.ee.tsinghua.edu.cn/publish/eeen/index.html" target=_blank>Department of Electronic Engineering</a>, School of Information Science and Technology, <a href="http://www.tsinghua.edu.cn/publish/newthuen/index.html" target=_blank>Tsinghua University</a>. 
				I studied as an exchange student in Electrical and Computer Engineering Department, <a href="https://www.utoronto.ca/" target=_blank>University of Toronto</a> in Fall 2014.</p>
			<p>I worked in <a href="http://ocrserv.ee.tsinghua.edu.cn/auto/index.asp" target=_blank>Center for Intelligent Image and Document Information Processing</a>, advised by <a href="http://www.cs.utsa.edu/~qitian/" target=_blank>Prof. Qi Tian(UTSA)</a> and <a href="http://www.ee.tsinghua.edu.cn/publish/eeen/3784/2010/20101219115647917992904/20101219115647917992904_.html" target="_blank">Prof. Liangrui Peng</a> since 2014.
				In Fall 2014, I spent 3 months wonderful time in Machine Learning Group in <a href="https://www.utoronto.ca/" target=_blank>University of Toronto</a> co-advised by <a href="http://www.cs.utoronto.ca/~fidler/" target=_blank>Prof. Sanja Fidler</a> and <a href="http://www.cs.toronto.edu/~urtasun/" target=_blank>Prof. Raquel Urtasun</a>.
				In Summer 2015, I worked at <a href="http://bvlc.eecs.berkeley.edu/" target=_blank>Berkeley Vision and Learning Center(BVLC)</a> and <a href="https://www.icsi.berkeley.edu/" target=_blank>International Computer Science Institute(ICSI)</a> as a research assistant, advised by <a href="http://www.eecs.berkeley.edu/~trevor/" target=_blank>Prof. Trevor Darrell</a> and <a href="https://sites.google.com/site/jshfeng/" target=_blank>Prof. Jiashi Feng</a>.</p>
			<p>My research interests lie in computer vision, deep learning, reinforcement learning and their applications. </p>

        <h2>Education</h2>
		
        <div class="media">
            <span class="pull-left"><img src="./images/tsinghua.png" width="96px" height="96px"/></span>
            <div class="media-body">
                <p><span style="font-weight: bold">Aug. 2012 - Jul. 2016 (Expected)</span>, Department of Electronic Engineering, <i><b>Tsinghua University</b></i>,</p>
                <p>Balchlor of Engineering, <b>GPA: 93/100, ranking: 5/238</b>.</ br> Average of Math and Math-Related Courses: <b>95.4/100</b>.</p>
            </div>  
        </div>

        <div class="media">
            <span class="pull-left"><img src="./images/toronto.png" width="96px" height="96px"/></span>
            <div class="media-body">
                <p><span style="font-weight: bold">Aug. 2014 - Dec. 2014</span>, School of Electrical and Computer Engineering, <i><b>University of Toronto</b></i>,</p>
                <p>Exchange Student, <b>GPA: 4.0/4.0</b>.</p>
            </div>
        </div>

        <div class="media">
            <span class="pull-left"><img src="./images/berkeley.png" width="96px" height="96px"/></span>
            <div class="media-body">
                <p><span style="font-weight: bold">July. 2015 - Sept. 2015</span>, Department of Electrical and Computer Engineering, <i><b>University of California, Berkeley</b></i>,</p>
                <p>Visiting Researcher.</p>
            </div>
        </div>
              

        <h2>Selected Research Projects</h2>
		
        <div class="media">
            <span class="pull-left"><img src="./images/proj1.png" width="96px" height="120px"/></span>
            <div class="media-body">
				<p><b>Weakly Supervised Deep Scene Parsing with Attributes</b>,</p>
				<p>Huazhe Xu, Jiashi Feng, Trevor Darrell,</p>
                <p>Jul 2015 - Nov 2015, <i><b>UC Berkeley</b></i>,</p>
                <!-- <p>In this work,  we consider a challenging problem of automatically parsing scene images with only weakly-supervised information. </ br>
					The core technique we develop to solve this problem  is a novel deep convolutional network architecture built on the fully convolutional network (FCN) model -- termed as category-attribute mutually boosted FCN (CAM-FCN).
					We formulate the problem of updating or training CAM-FCN  with non-linear global constraints  into an alternative optimization problem through decoupling the updating procedure of two sub-FCNs.
					Extensive experiments on benchmark datasets clearly demonstrate the superior effectiveness of CAM-FCN over well-established baselines for the weakly supervised scene parsing task.</p> -->
            </div>
        </div>

       <div class="media">
            <span class="pull-left"><img src="./images/proj2.png" width="96px" height="140px"/></span>
            <div class="media-body">
				<p><b>Natural Language Object Retrieval with RNN</b>,</p>
				<p>Ronghang Hu, Huazhe Xu, Marcus Rohrbach, Jiashi Feng, Kate Saenko and Trevor Darrell,</p>
                <p>Jul 2015 - Nov 2015, <i><b>UC Berkeley</b></i>,</p>
                <!-- <p>We address the task of natural language object retrieval, to localize a target object within a given image based on a natural language query of the object.
				Natural language object retrieval differs from text-based image retrieval task as it involves spatial information about objects within the scene and global scene context.
				To address this issue, we propose a novel Spatial Context Recurrent ConvNet (SCRC) model as scoring function on candidate boxes for object retrieval,
				integrating spatial conﬁgurations and global scene-level contextual information into the net-work.</p> -->
            </div>
        </div>

		<div class="media">
            <span class="pull-left"><img src="./images/proj3.png" width="96px" height="78px"/></span>
            <div class="media-body">
				<p><b>Automobile Visual Taste Ranking</b>,</p>
				<p>Huazhe Xu, Sanja Fidler, Raquel Urtasun,</p>
                <p>2015 Fall , <i><b>University of Toronto</b></i>,</p>
                <!-- <p>This project explores with issue of human's visual taste on automobiles.
					We find that most recommendation systems lack of personality and customized service. 
					We utilize image visual features and well-established survey questionaire with ranksvm and CNN techniques to detect personalized visual preference for customer. </p> -->
            </div>
        </div>
		
        <h2>Publications and Manuscripts</h2>
		<!--<h4>Conference Paper</h4>-->
		<ul>
	    <li><p>H. Gao<sup>*</sup>, <b>H. Xu<sup>*</sup></b>, Q. Cai, R. Wang, F. Yu, T. Darrell, 
Disentangling Propagation and Generation for Video Prediction, arXiv preprint</i>. <a href="https://arxiv.org/pdf/1812.00452.pdf">[pdf]</a> </li>
		</ul>
		<ul>
	    <li><p>H. Tang<sup>*</sup>, D. Lee<sup>*</sup>, J. Zhang,  <b>H. Xu</b>, T. Darrell, P. Abbeel, Modular Architecture for StarCraft II with Deep Reinforcement Learning. The 14th AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment (AIIDE'18)</i>. <a href="https://arxiv.org/pdf/1811.03555.pdf">[pdf]</a> </li>
		</ul>
		
		<ul>
	    <li><p>Y. Luo<sup>*</sup>, <b>H. Xu<sup>*</sup></b>, Y. Li, Y. Tian, T. Darrell, T. Ma, Algorithmic Framework for Model-based Reinforcement Learning with Theoretical Guarantees <i>. To appear at ICLR'19 (also appeared as ICMLW'18, NeurIPSW'18)</i>. <a href="https://arxiv.org/pdf/1807.03858.pdf">[pdf]</a> </li>
		</ul>
			
		<ul>
	    <li><p>Y. Gao<sup>*</sup>, <b>H. Xu<sup>*</sup></b>, F. Yu, S. Levine, T. Darrell, Reinforcement Learning from Imperfect Demonstrations<i>. in NIPS Deep RL Syposium</i>. <a href="https://arxiv.org/pdf/1802.05313.pdf">[pdf]</a></li>
		</ul>
	
		<ul>	
	    <li><p><b>H. Xu<sup>*</sup></b>, Y. Gao<sup>*</sup>, F. Yu, T. Darrell, End-to-end Learning of Driving Models from Large-scale Video Datasets.
                <i>in CVPR 2017 (<font color="red">oral</font>)</i>. <a href="https://arxiv.org/abs/1612.01079">[pdf]</a></p></li> 
        	</ul>
			
		<ul>
            <li><p>R. Hu, <b>H. Xu</b>, M. Rohrbach, J. Feng, K. Saenko, T. Darrell, Natural Language Object Retrieval.
                <i>in CVPR 2016 (<font color="red">oral</font>)</i>. <a href="http://arxiv.org/pdf/1511.04164.pdf">[pdf]</a></p></li> 
        	</ul>
	
		<ul>
			<li><p>Tian Xie, Qian Han, <b>Huazhe Xu</b>, Zihao Qi, Wenqian Shen. A Low-Complexity Linear Precoding Scheme Based on
SOR Method for Massive MIMO Systems. <i>Vehicular Technology Conference (VTC Spring), 2015 IEEE 81st ,
vol., no., pp.1-5, 11-14 May 2015</i>. <a href="">[pdf]</a></p></li>
		</ul>
	
		
        <h2>Honors and Awards</h2>
		<ul>
			<li><p>EECS Excellence Award, UC Berkeley, 2016</p></li>
			<li><p>Comprehensive Excellent Scholarship, Tsinghua Univ, 2013</p></li>
			<li><p>Academic Excellent Scholarship, Tsinghua, Univ, 2014</p></li>
			<li><p>Academic Excellent Scholarship, Tsinghua, Univ, 2015</p></li>
		</ul>

	<h2>News!</h2>
		<ul>
			<li><p>Nov 19, 2018, Our Starcraft 2 Project is covered by Synced (机器之心) and <a href=https://jack-clark.net/2018/11/19/import-ai-121-sony-researchers-make-ultra-fast-imagenet-training-breakthrough-berkeley-researchers-tackle-starcraft-ii-with-modular-rl-system-and-germany-adds-e3bn-for-ai-research/>Import AI</a>. </p></li>
		</ul>
		<ul>
			<li><p>Dec 18, 2017: Giving a talk at Berkeley DeepDrive Workshop. </p></li>
		</ul>
		<ul>
			<li><p>Oct 31, 2017: Giving a talk at <a href=https://sites.google.com/view/visionseminar>MIT vision seminar</a> in Boston. </p></li>
		</ul>
		<ul>
			<li><p>June 1, 2017: Giving a talk in at Tsinghua University in Beijing.</p></li>
		</ul>
		<ul>
			<li><p>Our paper 'End-to-end Learning of Driving Model from Largescale Dataset' appeared at 'New_era' Wechat Media. </p></li>
		</ul>
		<ul>
			<li><p>Interviewed by a 'Leiphone' reporter about BAIR Blog.</p></li>
		</ul>
	<h2>Service</h2>
		<ul>
			<li><p>Reviewer of ICLR’19</p></li>
		</ul>
		<ul>
			<li><p>Reviewer of ACCV’18</p></li>
		</ul>
		<ul>
			<li><p>Reviewer of NeurIPS’18</p></li>
		</ul>
		<ul>
			<li><p>Reviewer of ICML’18 ’19</p></li>
		</ul>
		<ul>
			<li><p>Reviewer of CVPR’18 ’19</p></li>
		</ul>
		<ul>
			<li><p>Reviewer of NIPS'17 Intelligent Transportation Workshop</p></li>
		</ul>
		<ul>
			<li><p>Reviewer of IEEE Transactions on Multimedia’ 16, 17</p></li>
		</ul>
		<ul>
			<li><p>Editor in BAIR Blog Editorial Board, manager of BAIR facebook handle.</p></li>
		</ul>
		
        <h2>Miscellaneous</h2>
		<ul>
	    <li><p><a href="https://www.goodreads.com/book/show/23422.The_Art_of_Travel?ac=1&from_search=true"> Alain De Botton: The Art of Travel (I traveled less often after reading this :p)</a></p></li>
            <li><p><a href="http://www.cs.toronto.edu/~fidler/CSC420.html">Introduction to Image Understanding (A lovely Course from Prof. Sanja Fidler)</a></p></li>
            <li><p><a href="https://www.youtube.com/watch?v=NSsKJIzwapA">Scriabin Etude op. 2 No. 1 in C sharp minor played by Horowitz (The piece of music I listened most often.)</a></p></li>
	    <li><p><a href="https://www.youtube.com/watch?v=lncNcNtGkJY">Franz Schubert Sonata D960(Kafka on The Shore novel by Murakami brought Schubert to me when I was 16. )</a></p></li>	
		</ul>
	
	<h2>Attempts</h2>
		Here is a partial catalog of my attempts at becoming more than what I am today. I doubt I will ever succeed totally but I hope I will never stop trying.
		<ul>
	     		<h4>Piano Project</h4> I am now learning to play the piano(again!) with pianist <a href="http://annerainwater.com/">Anne Rainwater</a>. Here are some pieces I enjoy playing recently: 
			<p style="text-indent:2em;"> Piano Sonata No. 3 in C major, Op. 2, No. 3, Ludwig van Beethoven</p>
			<p style="text-indent:2em;"> Impromptu in B-flat Major D. 935, No. 3 (Op. 142), Franz Schubert </p>
			<p style="text-indent:2em;"> French Suites, BWV 817, Johann Sebastian Bach</p>
			<p style="text-indent:2em;"> Prelude and Fugue No.2, Johann Sebastian Bach</p>
			<p style="text-indent:2em;"> 4 Improptus, D899, Franz Schubert</p>
			<p style="text-indent:2em;"> kinderszenen op. 15, Robert Schumann</p>
			<p style="text-indent:2em;"> Waltz in D-flat major, Op. 64, No. 1, Valse du petit chien, Frédéric Chopin</p>
			<p style="text-indent:2em;"> Grande valse brillante in E-flat major, Op. 18,  Frédéric Chopin</p>
			<p style="text-indent:2em;"> Tempest Sonata, Ludwig van Beethoven</p>
		</ul>
		<ul>
			<h4>Photography Project</h4> I will start my personal album soon to present some of my photography work.
		</ul>
		<ul>
			<h4>Reading Project</h4> I regularly read novels and books unrelated to Computer Science. I hope I can write some informal book review for the ones I read. The most current one is 'The Letters of Virginia Woolf'.
		</ul>
		<ul>
			<h4>Tennis</h4> I regularly play tennis every week. If you are visiting Berkeley and want to play, ping me on email.
		</ul>
	
      	<h2>Who searched for me!</h2>
		<br class="clearfix" />
                <div id="clustrmaps-widget"></div>
                <!--<script type="text/javascript" id="clstr_globe" src="//cdn.clustrmaps.com/globe.js?d=EvgNAh22dvx9JCt-FQ-UEUQ06TU2qe0ifBmBc0890K4"></script> -->
		<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=c2bfbf&w=a&d=mHndNXFUvtHvMdYMimBeCXb3NumiTYkNi8xKB-x2D2Q&co=ffffff&cmo=ff5353&cmn=ff5353&ct=000000'></script>
            </div>
    <script src="javascripts/scale.fix.js"></script>
  </body>
</html>
