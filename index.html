<!DOCTYPE html>
<html lang="en">
<head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src="https://www.googletagmanager.com/gtag/js?id=G-2ZFRQHQYP1"></script>
	<script>
	  window.dataLayer = window.dataLayer || [];
	  function gtag(){dataLayer.push(arguments);}
	  gtag('js', new Date());

	  gtag('config', 'G-2ZFRQHQYP1');
	</script>
	<link rel="stylesheet" type="text/css" href="./style/css">
	<link rel="stylesheet" type="text/css" href="./style/bootstrap.min.css">
	<link rel="stylesheet" type="text/css" href="./style/styles.css">
	<script src=""></script>
	<title>Huazhe Xu</title>
</head>

<body>

	<div class="my-container">
		<h1> Huazhe Xu </h1>
		<span>  <a href="https://scholar.google.com/citations?user=t9HPFawAAAAJ&hl=en">[Google Scholar]</a>  </span>

		<div class="btn-group btn-group-justified" role="group" aria-label="Justified button group">
			<a href="index.html" class="btn btn-default" role="button">Home</a>
			<a href="publication.html" class="btn btn-default" role="button">Publication</a>
			<a href="group.html" class="btn btn-default" role="button">Group</a>
			<a href="contact.html" class="btn btn-default" role="button">Contact</a>
			<a href="misc.html" class="btn btn-default" role="button">Misc</a>
    	</div>

    	<div class="content">
    		<div class="row">
				<div class="col-sm-4">
					<img class="img-responsive img-rounded" src="images/me2.jpeg">
				</div>
				<div class="col-sm-8">
					<p> I am a Tenure-Track Assistant Professor at <a href="https://iiis.tsinghua.edu.cn/en/">Institute for Interdisciplinary Information Sciences (IIIS), Tsinghua University</a>. I am leading the Tsinghua Embodied AI Lab (TEA Lab, <a href="images/pub-pic/tea.jpg">logo</a>), where we build robots and then bring intelligence to robots. </p>
					<p>I was a postdoctoral researcher at <a href="http://svl.stanford.edu/">Stanford Vision and Learning Lab (SVL)</a> advised by Prof. <a href="https://jiajunwu.com/">Jiajun Wu</a>. I obtained my Ph.D. in <a href="https://bair.berkeley.edu/">Berkeley AI Research (BAIR)</a> advised by Prof. <a href="https://people.eecs.berkeley.edu/~trevor/">Trevor Darrell</a>. I obtained my bachelor degree from Tsinghua University.</p>


<!--						I will be a postdoctoral fellow in <a href="https://ai.stanford.edu/">Stanford Artificial Intelligence Lab (SAIL)</a> from 2021 summer to 2022 summer. </p>-->

					<p><strong> I am hiring self-motivated Postdocs, Ph.D. students, Undergrads, and Research Interns at Tsinghua (base: Beijing, Shanghai). See more details in Chinese <a href="https://zhuanlan.zhihu.com/p/474570798">here</a>.</strong></p>
					<p><strong> Please email me with your CV directly. </strong> </p>


					<p>I support <a href="http://slow-science.org/">Slow Science</a>.
				</div>
    		</div>
        <h3>Research Topics</h3>
        <p>I am interested in <strong>Embodied AI</strong>: <strong>Reinforcement Learning</strong>, <strong>Robotics</strong>, and <strong>Computer Vision/Touch</strong>. Specifically, my research focuses on modeling the dynamics of the world, leveraging/finding human priors for policy learning, and further enabling algorithms to learn in a sample-efficient manner and generalize to unseen scenarios. I am also interested in solving complex real robot applications with deep learning and reinforcement learning. </p>

        <h3>News</h3>
        <ul>
			<li><p>I will serve as an associate editor in ICRA'24. </p></li>
			<li><p>Six papers are accepted by NeurIPS'23 including 1 in dataset and benchmark track. </p></li>
			<li><p>One paper is accepted by WACV'24. </p></li>
			<li><p>RoboCook is accepted by CoRL'23 (<strong style="color:red">oral</strong>). </p></li>
			<li><p>One paper is accepted by ICML'23. </p></li>
			<li><p>I will serve as an SPC member in IJCAI'23. </p></li>
			<li><p>Four papers are accepted by ICLR'23. </p></li>
			<li><p>Four papers are accepted by ICRA'23. </p></li>
			<li><p>Two papers are accepted by NeurIPS'22 (2 <strong style="color:red">spotlights</strong>). </p></li>
			<li><p>One paper is accepted by CoRL'22. </p></li>
			<li><p>Our paper "Scene Synthesis from Human Motion" is accepted by Siggraph Asia'22. </p></li>
			<li><p>Our paper "Towards Learning to Play Piano with Dexterous Hands and Touch" is accepted by IROS'22. </p></li>
			<li><p>Our RSS paper "RoboCraft" is covered by <a href="https://news.mit.edu/2022/robots-play-play-dough-0623">MIT Tech Review</a> and <a href="https://hai.stanford.edu/news/training-robot-shape-letters-play-doh">HAI</a>. </p></li>
			<li><p>Two papers are accepted by ICML'22. </p></li>
			<li><p>Our paper "Don't Touch What Matters" is accepted by IJCAI'22. </p></li>
			<li><p>I gave a talk at UC San Diego. </p></li>
			<li><p>Our paper RoboCraft is accepted by RSS'22. </p></li>
			<li><p>One paper is accepted by ICLR'22 (<strong style="color:red">spotlight</strong>). </p></li>
			<li><p>Two papers are accepted by NeurIPS'21. </p></li>
			<li><p>I became Dr. Xu on May 15, 2021. </p></li>
			<li><p>I gave a talk at MSRA, March 10, 2021. </p></li>
			<li><p>One paper is accepted by CVPR'21. </p></li>
			<li><p>Two papers are accepted by ICRA'21. </p></li>
			<li><p>Two papers are accepted by ICLR'21. </p></li>
			<li><p>I gave a talk at Nvidia, Nov, 2020. </p></li>
			<li><p>One papers is accepted by NeurIPS'20. </p></li>
			<li><p>One papers is accepted by ECCV'20. </p></li>
			<li><p>One papers is accepted by ICML'20 (<strong style="color:red">oral</strong>). </p></li>
        </ul>



    	</div>
      <br>
			<br>
      <br>
			<br>
      <br>
			<br>

    	<footer>
            <span>&copy;2022 Huazhe Xu with thanks to <a href="http://bootsnipp.com/" rel="nofollow">Bootsnipp</a>.</span>
        </footer>

	</div>

</body>
</html>
